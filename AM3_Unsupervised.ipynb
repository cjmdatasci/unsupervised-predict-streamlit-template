{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da10db9",
   "metadata": {},
   "source": [
    "# EDSA Movie Recommendation Challenge\n",
    "**Team AM3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ed8db",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://miro.medium.com/max/1838/1*3m0Jmc_k0NP3_CCwnwdB7Q.png\"\n",
    "     alt=\"Barnicles on your ship :( \"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=1000px/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a4545",
   "metadata": {},
   "source": [
    "# Connecting to Comet â˜„ï¸\n",
    "Comet enables data scientists and teams to track, compare, explain and optimize experiments and models across the model's entire lifecycle. Below we initials our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29ea603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/courtney/am3-unsupervised/3d5993a074f241789e59d51861a5bc16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"hmdqMkcAoZUZ1yvEyo00sxXho\",\n",
    "    project_name=\"am3-unsupervised\",\n",
    "    workspace=\"courtney\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457ca7a",
   "metadata": {},
   "source": [
    "# Introduction ðŸ’â€â™‚ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9b0a6",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f5cd5",
   "metadata": {},
   "source": [
    "Recommender systems are among the most popular applications of data science today. They are used to predict the \"rating\" or \"preference\" that a user would give to an item. Almost every major tech company has applied them in some form. Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow. Here, we will be using creating a recommender system to recommend movies to watch. \n",
    "\n",
    "We will be using 2 types of recommendation systems in our project, namely: Content based filtering and Collaborative based filtering as seen below-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab8921",
   "metadata": {},
   "source": [
    "We can gather that Content-based filtering, makes recommendations based on user preferences for product features. Collaborative filtering mimics user-to-user recommendations. It predicts users preferences as a linear, weighted combination of other user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf6572",
   "metadata": {},
   "source": [
    "### Objectives\n",
    " - To construct a `recommendation` algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    " - To compete in a `Kaggle` competition to find the best model for the job.\n",
    " - To share our findings witih an assessment board and via a `Streamlit app` to the world.\n",
    " - To achieve the lowest `RMSE` score possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac28704",
   "metadata": {},
   "source": [
    "### Data Overview "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15bd23",
   "metadata": {},
   "source": [
    "This dataset consists of several million 5-star ratings obtained from users of the online MovieLens movie recommendation service. The MovieLens dataset has long been used by industry and academic researchers to improve the performance of explicitly-based recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f8b49",
   "metadata": {},
   "source": [
    "## Importing the libraries ðŸ§°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c3961",
   "metadata": {},
   "source": [
    "Here, we import various packages and modules which enable us to perform many different tasks, such as manipulating the data, viewing the data, performing calculations of the data and visualizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e630ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:14.094613Z",
     "iopub.status.busy": "2021-07-02T17:26:14.094261Z",
     "iopub.status.idle": "2021-07-02T17:26:14.115030Z",
     "shell.execute_reply": "2021-07-02T17:26:14.113967Z",
     "shell.execute_reply.started": "2021-07-02T17:26:14.094584Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import os\n",
    "import pickle\\\n",
    "\n",
    "import warnings\n",
    "from surprise import accuracy\n",
    "from time import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "import heapq\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from surprise import CoClustering\n",
    "from surprise import SlopeOne\n",
    "from surprise import NMF\n",
    "from surprise import SVDpp\n",
    "from surprise import SVD, NormalPredictor, BaselineOnly, NMF, SlopeOne, CoClustering\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import squarify\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "\n",
    "# Packages for model evaluation\n",
    "\n",
    "# Package to suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbe122",
   "metadata": {},
   "source": [
    "## Loading the datasets ðŸ“¡\n",
    "\n",
    "We must now load the data we will be using. The data we have received is in .csv (comma separated values) format, so to access the data through python, we use pandas (pd.read). We have 2 files which contain the train and test data respectively. The test data is a subset of train, and we use this method to ensure that the models we build are safe from data leakage and therefore, are of better quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\sample_submission.csv\")\n",
    "df_movies = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\movies.csv\")\n",
    "df_imdb = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\imdb_data.csv\",dtype = {'movieId': 'int32'})\n",
    "df_genome_scores = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\genome_scores.csv\", index_col='movieId')\n",
    "df_genome_tags = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\genome_tags.csv\")\n",
    "df_train = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\test.csv\")\n",
    "df_tags = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\tags.csv\")\n",
    "df_links = pd.read_csv(r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\links.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1779607",
   "metadata": {},
   "source": [
    "# EDAðŸ”Ž\n",
    "Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48539161",
   "metadata": {},
   "source": [
    "### Understanding the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026908e",
   "metadata": {},
   "source": [
    "**Movies DataFrame**\n",
    "\n",
    "Here we perform a basic analysis of the movies dataframe. We begin by generating the head of the dataframe below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715ae70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.267027Z",
     "iopub.status.busy": "2021-07-02T17:26:25.266746Z",
     "iopub.status.idle": "2021-07-02T17:26:25.277109Z",
     "shell.execute_reply": "2021-07-02T17:26:25.276250Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.266997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top 5 rows of dataframe\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58043e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75e387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.279237Z",
     "iopub.status.busy": "2021-07-02T17:26:25.278911Z",
     "iopub.status.idle": "2021-07-02T17:26:25.304755Z",
     "shell.execute_reply": "2021-07-02T17:26:25.303878Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.279196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Information about the dataframe\n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe388d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.306637Z",
     "iopub.status.busy": "2021-07-02T17:26:25.306257Z",
     "iopub.status.idle": "2021-07-02T17:26:25.320366Z",
     "shell.execute_reply": "2021-07-02T17:26:25.319590Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.306598Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f077b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.321907Z",
     "iopub.status.busy": "2021-07-02T17:26:25.321414Z",
     "iopub.status.idle": "2021-07-02T17:26:25.338016Z",
     "shell.execute_reply": "2021-07-02T17:26:25.337304Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.321879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top 20 genres by count:\n",
    "df_genres = df_movies[\"genres\"].value_counts()\n",
    "df_genres.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f895ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottom 20 genres by volume:\n",
    "df_genres = df_movies[\"genres\"].value_counts()\n",
    "df_genres.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2ce3d",
   "metadata": {},
   "source": [
    "Surprisingly, the top genres by volume contain only one or two genre types, whereas the worst genres have several genre types. This is likely due to the fact that certain films are more esoteric and infrequent, resulting in a smaller dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68861452",
   "metadata": {},
   "source": [
    "**The basic analysis of the Movies DataFrame is summarized here:**\n",
    "\n",
    "There are 62423 rows and 3 columns in the movies dataframe (movieId, title and genres). There are duplicate titles in 98 of the rows. There are 1639 distinct genres listed, including blended genres. There are 5062 movies without a genre assigned to them, and the three most popular genres are drama, comedy, and documentary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8c512",
   "metadata": {},
   "source": [
    "**IMDB Data**\n",
    "\n",
    "We explore the IMBD data to learn more about the content of the movies and who worked on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5daa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.339224Z",
     "iopub.status.busy": "2021-07-02T17:26:25.338875Z",
     "iopub.status.idle": "2021-07-02T17:26:25.361534Z",
     "shell.execute_reply": "2021-07-02T17:26:25.360579Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.339197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_imdb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab2019",
   "metadata": {},
   "source": [
    "Here we see that there are only 27277 movies in this dataframe, which is less than the 48213 movies in the ratings dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89537e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.362896Z",
     "iopub.status.busy": "2021-07-02T17:26:25.362573Z",
     "iopub.status.idle": "2021-07-02T17:26:25.383859Z",
     "shell.execute_reply": "2021-07-02T17:26:25.382725Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.362867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Information about the dataframe\n",
    "df_imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0012cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.387701Z",
     "iopub.status.busy": "2021-07-02T17:26:25.387399Z",
     "iopub.status.idle": "2021-07-02T17:26:25.402213Z",
     "shell.execute_reply": "2021-07-02T17:26:25.401508Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.387669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_imdb.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc2141",
   "metadata": {},
   "source": [
    "**Basic examination of the IMDB DataFrame summarized:**\n",
    "\n",
    "There are 27278 rows and 6 columns in the IMDB Dataframe (movieId, title cast, director, runtime, budget, and plot keywords). The only column that does not have any null entries is MovieId."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e1527",
   "metadata": {},
   "source": [
    "**Genome Scores DataFrame**\n",
    "\n",
    "We'll look at the genomic scores data in this section. This dataset contains scores that indicate how relevant a tag is to a film.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e868aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.404306Z",
     "iopub.status.busy": "2021-07-02T17:26:25.403548Z",
     "iopub.status.idle": "2021-07-02T17:26:25.413228Z",
     "shell.execute_reply": "2021-07-02T17:26:25.412204Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.404270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_genome_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_genome_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aec605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.414630Z",
     "iopub.status.busy": "2021-07-02T17:26:25.414367Z",
     "iopub.status.idle": "2021-07-02T17:26:25.435082Z",
     "shell.execute_reply": "2021-07-02T17:26:25.433597Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.414604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Information about the dataframe\n",
    "df_genome_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a211849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.436581Z",
     "iopub.status.busy": "2021-07-02T17:26:25.436302Z",
     "iopub.status.idle": "2021-07-02T17:26:25.520521Z",
     "shell.execute_reply": "2021-07-02T17:26:25.519386Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.436554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_genome_scores.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6dfa16",
   "metadata": {},
   "source": [
    "**Summary of the Genome Scores DataFrame**\n",
    "\n",
    "The Genome Scores Dataframe has 15'584'448 rows and 3 columns (movieId, tagId and relevance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f43df",
   "metadata": {},
   "source": [
    "**Genome Tags DataFrame**\n",
    "\n",
    "Here we explore the tag data. These tags are assigned by a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6add6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.522592Z",
     "iopub.status.busy": "2021-07-02T17:26:25.522120Z",
     "iopub.status.idle": "2021-07-02T17:26:25.532834Z",
     "shell.execute_reply": "2021-07-02T17:26:25.531802Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.522543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_genome_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_genome_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8070b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.534627Z",
     "iopub.status.busy": "2021-07-02T17:26:25.534351Z",
     "iopub.status.idle": "2021-07-02T17:26:25.555333Z",
     "shell.execute_reply": "2021-07-02T17:26:25.554300Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.534599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Information about the dataframe\n",
    "df_genome_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c5548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.556866Z",
     "iopub.status.busy": "2021-07-02T17:26:25.556559Z",
     "iopub.status.idle": "2021-07-02T17:26:25.578773Z",
     "shell.execute_reply": "2021-07-02T17:26:25.577468Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.556834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_genome_tags.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfa5e7",
   "metadata": {},
   "source": [
    "**Summary Genome Tags DataFrame**\n",
    "The Genome Tags Dataframe has 1'128 rows and 2 columns (tagId and tag). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743f6ce",
   "metadata": {},
   "source": [
    "**Links DataFrame**\n",
    "\n",
    "Here we explore the links dataframe. From Kaggle, this data serves as a link between a MovieLens ID and the IMDB and TMDB IDs associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550eb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.580607Z",
     "iopub.status.busy": "2021-07-02T17:26:25.580072Z",
     "iopub.status.idle": "2021-07-02T17:26:25.597735Z",
     "shell.execute_reply": "2021-07-02T17:26:25.596640Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.580569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd8eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.599760Z",
     "iopub.status.busy": "2021-07-02T17:26:25.599160Z",
     "iopub.status.idle": "2021-07-02T17:26:25.619267Z",
     "shell.execute_reply": "2021-07-02T17:26:25.618532Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.599721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gather information about the dataframe\n",
    "df_links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07fcf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.620726Z",
     "iopub.status.busy": "2021-07-02T17:26:25.620270Z",
     "iopub.status.idle": "2021-07-02T17:26:25.627810Z",
     "shell.execute_reply": "2021-07-02T17:26:25.626983Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.620687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_links.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c02b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.629253Z",
     "iopub.status.busy": "2021-07-02T17:26:25.628835Z",
     "iopub.status.idle": "2021-07-02T17:26:25.642574Z",
     "shell.execute_reply": "2021-07-02T17:26:25.641791Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.629222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop all null values in links Dataframe\n",
    "df_links.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124ffa4",
   "metadata": {},
   "source": [
    "**Summary of the Links DataFrame**\n",
    "\n",
    "The links dataframe has 62'423 rows and 3 columns (movieId, imdbId and tmdbId). 107 of the tmdbId's are null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639336bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:13:26.790352Z",
     "iopub.status.busy": "2021-07-02T17:13:26.789925Z",
     "iopub.status.idle": "2021-07-02T17:13:26.800665Z",
     "shell.execute_reply": "2021-07-02T17:13:26.799111Z",
     "shell.execute_reply.started": "2021-07-02T17:13:26.790260Z"
    }
   },
   "source": [
    "**Tags Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f559a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.644562Z",
     "iopub.status.busy": "2021-07-02T17:26:25.644183Z",
     "iopub.status.idle": "2021-07-02T17:26:25.656910Z",
     "shell.execute_reply": "2021-07-02T17:26:25.656058Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.644521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87cb592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.658621Z",
     "iopub.status.busy": "2021-07-02T17:26:25.658119Z",
     "iopub.status.idle": "2021-07-02T17:26:25.746455Z",
     "shell.execute_reply": "2021-07-02T17:26:25.745731Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.658585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gather information about the dataframe\n",
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce13fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics summary\n",
    "df_tags['tag'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbc279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.747918Z",
     "iopub.status.busy": "2021-07-02T17:26:25.747550Z",
     "iopub.status.idle": "2021-07-02T17:26:25.806819Z",
     "shell.execute_reply": "2021-07-02T17:26:25.805515Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.747891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_tags.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop the rows with null values\n",
    "df_tags = df_tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells us count of each tag in descending order.\n",
    "df_tags.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dupplicate entries: {}'.format(df_tags.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac28d5",
   "metadata": {},
   "source": [
    "**Train Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3ff0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.809052Z",
     "iopub.status.busy": "2021-07-02T17:26:25.808646Z",
     "iopub.status.idle": "2021-07-02T17:26:25.820260Z",
     "shell.execute_reply": "2021-07-02T17:26:25.819266Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.809017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf72717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9eb213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.826822Z",
     "iopub.status.busy": "2021-07-02T17:26:25.826474Z",
     "iopub.status.idle": "2021-07-02T17:26:25.842440Z",
     "shell.execute_reply": "2021-07-02T17:26:25.841393Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.826792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gather information about the dataframe\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b65988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.845383Z",
     "iopub.status.busy": "2021-07-02T17:26:25.844778Z",
     "iopub.status.idle": "2021-07-02T17:26:25.946722Z",
     "shell.execute_reply": "2021-07-02T17:26:25.945716Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.845336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98baa66d",
   "metadata": {},
   "source": [
    "**Test Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a083a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.947972Z",
     "iopub.status.busy": "2021-07-02T17:26:25.947670Z",
     "iopub.status.idle": "2021-07-02T17:26:25.956101Z",
     "shell.execute_reply": "2021-07-02T17:26:25.955017Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.947942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display top 5 rows of dataframe\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the shape of the data\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c1de2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.957646Z",
     "iopub.status.busy": "2021-07-02T17:26:25.957344Z",
     "iopub.status.idle": "2021-07-02T17:26:25.976914Z",
     "shell.execute_reply": "2021-07-02T17:26:25.975597Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.957613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gather information about the dataframe\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a7193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:25.978338Z",
     "iopub.status.busy": "2021-07-02T17:26:25.978036Z",
     "iopub.status.idle": "2021-07-02T17:26:26.005582Z",
     "shell.execute_reply": "2021-07-02T17:26:26.004585Z",
     "shell.execute_reply.started": "2021-07-02T17:26:25.978307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if dataframe as any null values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62ffe9",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "Data visualization is the presentation of data in a pictorial or graphical format. It enables decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns. With interactive visualization, you can take the concept a step further by using technology to drill down into charts and graphs for more detail, interactively changing what data you see and how itâ€™s processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3696dd",
   "metadata": {},
   "source": [
    "#### Visualizing Genre's\n",
    "A film genre is a stylistic or thematic category for motion pictures based on similarities either in the narrative elements, aesthetic approach, or the emotional response to the film.\n",
    "Below we will try and gain insight on the various genres found in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194ac79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:29.233259Z",
     "iopub.status.busy": "2021-07-02T17:26:29.232892Z",
     "iopub.status.idle": "2021-07-02T17:26:29.484850Z",
     "shell.execute_reply": "2021-07-02T17:26:29.483927Z",
     "shell.execute_reply.started": "2021-07-02T17:26:29.233229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3722cc3e",
   "metadata": {},
   "source": [
    "From the plot below, we can gather that the most common genres are Drama, comedy and thrillers. From this information, we can gather that viewers are most intrigued by the above-mentioned genres as these movies are produced the most.\n",
    "We have also noticed that IMAX is the least favored genre, although this can be ambiguous as IMAX is more of an experience than a genre, as movies can have their own specific genre but still be seen normal cinemas as compared to an IMAX cinema. IMAX movies are made for huge theater screens with high quality special fx, therefore one might deduce that its count is low due to a higher budget for the above-mentioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bf0f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:31:27.838577Z",
     "iopub.status.busy": "2021-07-02T17:31:27.838036Z",
     "iopub.status.idle": "2021-07-02T17:31:28.165163Z",
     "shell.execute_reply": "2021-07-02T17:31:28.164207Z",
     "shell.execute_reply.started": "2021-07-02T17:31:27.838537Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the genres from most common to least common\n",
    "plot = plt.figure(figsize=(10, 6))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(\n",
    "                  ascending=False).index,\n",
    "              palette='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f41824f",
   "metadata": {},
   "source": [
    "Let us now understand the amount of times a specific genre are have the most number of movies in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc8b14",
   "metadata": {},
   "source": [
    "#### Visualizing Rating's "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0bc73",
   "metadata": {},
   "source": [
    "Ratings play an important role in our dataset, as, this describes how a user rates a movie on a scale of 1-5, with 5 being the best.\n",
    "\n",
    "We will revisit ratings when building our models, later on in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fb953",
   "metadata": {},
   "source": [
    "Below we will create the ratings dataframe by merging the movies and train dataframe's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe84fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:29.801065Z",
     "iopub.status.busy": "2021-07-02T17:26:29.800782Z",
     "iopub.status.idle": "2021-07-02T17:26:31.667079Z",
     "shell.execute_reply": "2021-07-02T17:26:31.665964Z",
     "shell.execute_reply.started": "2021-07-02T17:26:29.801036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the ratings dataframe\n",
    "df = pd.merge(df_train, df_movies, on='movieId')\n",
    "df.groupby('title')['rating'].mean().sort_values(ascending=False)\n",
    "df.groupby('title')['rating'].count().sort_values(ascending=False)\n",
    "ratings = pd.DataFrame(df.groupby('title')['rating'].mean())\n",
    "ratings['num_ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())\n",
    "df_rat = ratings.sort_values(by=['num_ratings'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7301e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:37.294376Z",
     "iopub.status.busy": "2021-07-02T17:26:37.294088Z",
     "iopub.status.idle": "2021-07-02T17:26:37.543205Z",
     "shell.execute_reply": "2021-07-02T17:26:37.542278Z",
     "shell.execute_reply.started": "2021-07-02T17:26:37.294348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a plot of the number of ratings\n",
    "f, axarr = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axarr[0].hist(ratings['num_ratings'], bins=10, color=\"skyblue\")\n",
    "axarr[0].set_title('Number of ratings\\n', fontsize=25)\n",
    "\n",
    "# Create a plot showing the average ratings distribution\n",
    "axarr[1].hist(ratings['rating'], bins=10, color=\"skyblue\")\n",
    "axarr[1].set_title('Average ratings\\n', fontsize=25)\n",
    "\n",
    "# Display both plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad3f9f",
   "metadata": {},
   "source": [
    "Above, we can deduce that the most common rating is 3.5. Viewers are generally rating movies as average or as above-average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa7d06",
   "metadata": {},
   "source": [
    "Here we a distribution plot as well as a box and whisker plot. In descriptive statistics, a box plot or boxplot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending from the boxes indicating variability outside the upper and lower quartiles, hence the terms box-and-whisker plot and box-and-whisker diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc4cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:37.687902Z",
     "iopub.status.busy": "2021-07-02T17:26:37.687640Z",
     "iopub.status.idle": "2021-07-02T17:26:37.912170Z",
     "shell.execute_reply": "2021-07-02T17:26:37.911149Z",
     "shell.execute_reply.started": "2021-07-02T17:26:37.687877Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.boxplot(ratings.rating, ax=ax[0], color=\"skyblue\")\n",
    "sns.distplot(ratings.rating, ax=ax[1], color=\"skyblue\")\n",
    "plt.title('Distribution of Type Ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5ca47",
   "metadata": {},
   "source": [
    "- From the histogram, we observe that most people have given ratings 3 and 4\n",
    "- We also see that it follows a normal distribution, guasian curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cb21a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T17:26:37.913545Z",
     "iopub.status.busy": "2021-07-02T17:26:37.913297Z",
     "iopub.status.idle": "2021-07-02T17:27:15.574762Z",
     "shell.execute_reply": "2021-07-02T17:27:15.573661Z",
     "shell.execute_reply.started": "2021-07-02T17:26:37.913521Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = sns.jointplot(x='rating', y='num_ratings',\n",
    "                    data=ratings, alpha=0.5, height=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212584b1",
   "metadata": {},
   "source": [
    "From the scatter plot above, we see that between ratings 3 & 4, the ratings are densely concentrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eaf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_plot_by_ratings(df,column, n):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    data = df[str(column)].value_counts().head(n)\n",
    "    ax = sns.barplot(y = data.index, x = data, order= data.index, palette='Blues', edgecolor=\"black\")\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width()/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n",
    "    plt.title(f'Top {n} {column.title()} by Number of Ratings', fontsize=14)\n",
    "    plt.xlabel(column.title())\n",
    "    plt.ylabel('Number of Ratings')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeeca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.merge(df_train, df_movies, on='movieId', how='inner')\n",
    "full_movies = pd.merge(movies, df_imdb, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_plot_by_ratings(movies, 'title', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0c028",
   "metadata": {},
   "source": [
    "We see that Shawshank redemption is the highest rated movie in the dataset. One of the reasons could be due to its release date, which allowed more ratings over time and the fact that users like the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47841364",
   "metadata": {},
   "source": [
    "#### Visualizing Movies metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe60efa",
   "metadata": {},
   "source": [
    "Here we create a function that will enable us to visualize a scatterplot of the ratings dataframe. We will us it to visualize the highly rated and poorly rated movies with 500 or more ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie = pd.read_csv(\n",
    "    r\"C:\\Users\\court\\Desktop\\AdvUnsupPre\\edsa-movie-recommendation-challenge\\movies.csv\", index_col='movieId')\n",
    "\n",
    "\n",
    "def plot_ratings(count, n, palette='Blues', best=True, method='mean'):\n",
    "\n",
    "    # What are the best and worst movies\n",
    "    # Creating a new DF with mean and count\n",
    "    if method == 'mean':\n",
    "        movie_avg_ratings = pd.DataFrame(df_train.join(\n",
    "            df_movie, on='movieId', how='left').groupby(['movieId', 'title'])['rating'].mean())\n",
    "    else:\n",
    "        movie_avg_ratings = pd.DataFrame(df_train.join(\n",
    "            df_movie, on='movieId', how='left').groupby(['movieId', 'title'])['rating'].median())\n",
    "    movie_avg_ratings['count'] = df_train.groupby(\n",
    "        'movieId')['userId'].count().values\n",
    "    movie_avg_ratings.reset_index(inplace=True)\n",
    "    movie_avg_ratings.set_index('movieId', inplace=True)\n",
    "\n",
    "    # Remove movies that have been rated fewer than n times\n",
    "    data = movie_avg_ratings[movie_avg_ratings['count'] > count]\n",
    "    data.sort_values('rating', inplace=True, ascending=False)\n",
    "    if best == True:\n",
    "        plot = data.head(n).sort_values('rating', ascending=False)\n",
    "        title = 'Best Rated'\n",
    "        plt.figure(figsize=(10, 6))\n",
    "    else:\n",
    "        plot = data.tail(n).sort_values('rating', ascending=False)\n",
    "        title = 'Worst Rated'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=plot['rating'], y=plot['title'], palette='Blues')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('')\n",
    "    plt.tick_params(axis='y', which='both', labelleft=False, labelright=True)\n",
    "    plt.title(f'Top {n} {title} Movies with Over {count} Ratings', fontsize=14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b24a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the top 10 highest rated titles\n",
    "plot_ratings(10000, 15, 'blue', True, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417452c",
   "metadata": {},
   "source": [
    "From the plot above, we find that the most popular movies are predictable titles when we filter out movies with less than 10000 ratings. Unsurprisingly, The Shawshank Redemption and The Godfather are at the top of the list. It's worth noting that films released after 2000 are underrepresented. Are there any movies that users prefer to see that are older?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the 10 worst rated titles?\n",
    "plot_ratings(500, 15, 'blue', False, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddfa53",
   "metadata": {},
   "source": [
    "People did not like Battlefield too much and with 1200 ratings, they really wanted it to be known. It is interesting how many sequels appear in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72080d9",
   "metadata": {},
   "source": [
    "Now we shall create a function to count the most common directors in the IMDB dataframe by filtering directors who have made 10 movies or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_directors(df, count=10):\n",
    "    directors = pd.DataFrame(df['director'].value_counts()).reset_index()\n",
    "    directors.columns = ['director', 'count']\n",
    "    # Lets only take directors who have made 10 or more movies otherwise we will have to analyze 11000 directors\n",
    "    directors = directors[directors['count'] >= count]\n",
    "    return directors.sort_values('count', ascending=False)\n",
    "\n",
    "\n",
    "directors = count_directors(df_imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6c6eb",
   "metadata": {},
   "source": [
    "Here we create a function to plot our popular Movie Directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_count(df, column):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(y=df[f'{column}'], x=df['count'],\n",
    "                     palette='Blues', orient='h')\n",
    "    plt.title(f'Number of Movies Per {column}', fontsize=14)\n",
    "    plt.ylabel(f'{column}')\n",
    "    plt.xlabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting top 10 movie directors using a count-plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "director = df_imdb['director']  # .explode()\n",
    "axes = sns.countplot(\n",
    "    y=director, order=director.value_counts().index[1:11], palette='Blues')\n",
    "axes.set_title('Number of movies per Director', fontsize=15)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7b205",
   "metadata": {},
   "source": [
    "From the barplot above we see that Woody Allen and Luc Besson are tied for first place for most popular movie directors.\n",
    "\n",
    "And the same directors are at the top of the list for most number of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting popular cast using a count-plot\n",
    "df_imdb['title_cast'] = df_imdb['title_cast'].str.split(\n",
    "    '|')  # spliting the title cast into a list\n",
    "plt.figure(figsize=(10, 6))\n",
    "title_cast = df_imdb['title_cast'].explode()\n",
    "ax = sns.countplot(\n",
    "    y=title_cast, order=title_cast.value_counts().index[:9], palette='Blues')\n",
    "ax.set_title('Top 10 Popular Actors', fontsize=15)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339be3e",
   "metadata": {},
   "source": [
    "As we can see in the diagram above, Samuel L Jackson was the popular cast as he appeared in over 80 movies from our database. Steve Buscemi coming in 2nd with over 60 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# Creating a wordcloud of the movie titles to view the most popular movie titles withtin the word cloud\n",
    "df_movies['title'] = df_movies['title'].fillna(\"\").astype('str')\n",
    "title_corpus = ' '.join(df_movies['title'])\n",
    "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='black',\n",
    "                            height=2000, width=4000).generate(title_corpus)\n",
    "\n",
    "# Plotting the wordcloud\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(title_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c5d2f",
   "metadata": {},
   "source": [
    "We have created a wordcloud, to highlight popular movie titles based on frequency and relevance. \n",
    "- The popular movie genre is Drama followed by Comedy.\n",
    "- This corroborates with the most frequent movie titles above.\n",
    "- 'Love', 'Girl', 'Man', 'Life', 'Story', 'Night' are words found in most drama titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f51b30",
   "metadata": {},
   "source": [
    "**Runtime Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a threshold\n",
    "threshb = 200\n",
    "thresh_dfb = df_imdb[df_imdb['runtime'] <= threshb]\n",
    "\n",
    "#Plotting distribution of movies's duration using dist-plot\n",
    "plt.figure(figsize = (10,6))\n",
    "axes=sns.distplot(thresh_dfb['runtime'],color='blue', kde=True)\n",
    "axes.set_title('Runtime Distribution',fontsize=15)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4fa20",
   "metadata": {},
   "source": [
    "We created a threshold for our visulaization because we have outliers in our dataset.\n",
    "From the plot above we can note a few things:\n",
    "- The plot follows a normal distribution , the probability distribution is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean.\n",
    "- The range for runtime is from around 1min - 14,62hrs\n",
    "- The average movie runtime is 1,67hrs \n",
    "- The longest movie is 14,62 hrs and is a TV show (series) called 'Taken' directed by Dakota Fanning and had a budget of $40,000,000.\n",
    "- The shorted movies are is 1 min long are trailers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b30fd5",
   "metadata": {},
   "source": [
    "Here we merge the train and movie dataframes to gain insight on the ratings feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the release year from the movie titles\n",
    "df_movies['release_year'] = df_movies.title.map(lambda x: re.findall('\\d\\d\\d\\d', x))\n",
    "df_movies.release_year = df_movies.release_year.apply(lambda x: np.nan if not x else int(x[-1]))\n",
    "years =  pd.DataFrame(df_movies.groupby(['release_year'])['title'].count())\n",
    "years.rename(columns={'title':'movies released'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a threshold, to show only years in which more than 5 movies were released.\n",
    "thresh = 5\n",
    "thresh_df = years[years['movies released'] >= thresh]\n",
    "\n",
    "#lets create the line plot\n",
    "fig = px.line(thresh_df, y='movies released', title= 'Movies released per year')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af014897",
   "metadata": {},
   "source": [
    "The movie release dates range from as early as 1003 to 2019. Before the 1900s there were less than 5 movies produced per year, therefore we have set our threshold to 5.\n",
    "- There was a movie production boom in the early 2000, peaking around 2015 with 2515 movies produced.\n",
    "- The recession in the USA might have contributed to the further decline in movie production around 2018.\n",
    "- We expect the lowest numbers of movies produced to be in 2020 due to the pandemic, Covid19."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4d3ba",
   "metadata": {},
   "source": [
    "How many movies do we have?\n",
    "\n",
    "We are curious to find out the proportion of movies in the dataframe versus the total number of rated movies total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of unique movies in the movies dataframe\n",
    "num1 = len(df_movies.movieId.unique())\n",
    "print('The number of unique movies in the dataframe is:', num1)\n",
    "\n",
    "#the number of unique movies rated\n",
    "num2 = len(df_train.movieId.unique())\n",
    "print('The number of unique movies rated is:', num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ea812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a pie chart \n",
    "pi_data = [['Total Movies', 62423], ['Rated Movies', 48213]] \n",
    "df_pi = pd.DataFrame(pi_data, columns = ['Movies', 'Count']) \n",
    "\n",
    "df_pi.plot.pie(y='Count', figsize=(5,5),labels=df_pi['Movies'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09adb3",
   "metadata": {},
   "source": [
    "# Data Preprocessing ðŸ“Š\n",
    "Data preprocessing is an important step in the data mining process. The phrase \"garbage in, garbage out\" is particularly applicable to data mining and machine learning projects. Data-gathering methods are often loosely controlled, resulting in out-of-range values, impossible data combinations, and missing values, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe0385",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "Content-based filtering recommends items based on a comparison between the content of the items and a user profile. The content of each item is represented as a set of descriptors or terms, typically the words that occur in a document. In the following section, the model uses genres as keywords to recommend similar movies based on input from a user. The model was not used to predict ratings for the testing data, as it is too computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac13006",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 400px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://miro.medium.com/max/500/1*BME1JjIlBEAI9BV5pOO5Mg.png\"\n",
    "     alt=\"Barnicles on your ship :( \"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=300px/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2d4f4",
   "metadata": {},
   "source": [
    "Below we create a function to process the data for the content based filtering algorithm. We include parameters such as the number of movies used within the dataset.\n",
    "\n",
    "Thereafter the function performs filtering based on the list of movies supplied by the user and produces 10 recommendations based on the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(subset_size):\n",
    "\n",
    "    # Split genre data into individual words.\n",
    "    movies['keyWords'] = movies['genres'].str.replace('|', ' ')\n",
    "    # Subset of the data\n",
    "    movies_subset = movies[:subset_size]\n",
    "    return movies_subset\n",
    "\n",
    "\n",
    "def content_model(movie_list, top_n=10):\n",
    "\n",
    "    # Initializing the empty list of recommended movies\n",
    "    data = data_preprocessing(2000)\n",
    "    # Instantiating and generating the count matrix\n",
    "    count_vec = CountVectorizer()\n",
    "    count_matrix = count_vec.fit_transform(data['keyWords'])\n",
    "    indices = pd.Series(data['title'])\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "    cosine_sim = pd.DataFrame(cosine_sim, index=data.index, columns=data.index)\n",
    "    # Getting the index of the movie that matches the title\n",
    "    idx_1 = indices[indices == movie_list[0]].index[0]\n",
    "    idx_2 = indices[indices == movie_list[1]].index[0]\n",
    "    idx_3 = indices[indices == movie_list[2]].index[0]\n",
    "    # Creating a Series with the similarity scores in descending order\n",
    "    rank_1 = cosine_sim[idx_1]\n",
    "    rank_2 = cosine_sim[idx_2]\n",
    "    rank_3 = cosine_sim[idx_3]\n",
    "    # Calculating the scores\n",
    "    score_series_1 = pd.Series(rank_1).sort_values(ascending=False)\n",
    "    score_series_2 = pd.Series(rank_2).sort_values(ascending=False)\n",
    "    score_series_3 = pd.Series(rank_3).sort_values(ascending=False)\n",
    "    # Getting the indexes of the 10 most similar movies\n",
    "    listings = score_series_1.append(score_series_2).append(\n",
    "        score_series_3).sort_values(ascending=False)\n",
    "    # Store movie names\n",
    "    recommended_movies = []\n",
    "    # Appending the names of movies\n",
    "    top_50_indexes = list(listings.iloc[1:50].index)\n",
    "    # Removing chosen movies\n",
    "    top_indexes = np.setdiff1d(top_50_indexes, [idx_1, idx_2, idx_3])\n",
    "    for i in top_indexes[:top_n]:\n",
    "        recommended_movies.append(list(movies['title'])[i])\n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8213f6d",
   "metadata": {},
   "source": [
    "Below we test out the funtion by using a single movie title from the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = df_movies.dropna()\n",
    "movie_list = ['Grumpier Old Men (1995)', 'Ace Ventura: When Nature Calls (1995)',\n",
    "              'Father of the Bride Part II (1995)']\n",
    "content_model(movie_list, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46595f",
   "metadata": {},
   "source": [
    "As mentioned, the function provides 10 recommendations based on the selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a6041",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n",
    "Collaborative filtering filters information by using the interactions and data collected by the system from other users. It's based on the idea that people who agreed in their evaluation of certain items are likely to agree again in the future.\n",
    "\n",
    "\n",
    "Collaborative filtering can then be divided into 2 subsets, namely **Item** and **User** based collaborative filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596cc4c",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 400px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://miro.medium.com/max/500/1*x8gTiprhLs7zflmEn1UjAQ.png\"\n",
    "     alt=\"Barnicles on your ship :( \"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=450px/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdfb66",
   "metadata": {},
   "source": [
    "- User-Based Collaborative Filtering:\n",
    "This method aims at finding similar users and recommendations are made to a user based on what a similar user has liked.\n",
    "- Item Based Collaborative Filtering: Here, new items are recommended to users based on their similarity with the items that the user has rated- highly in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4a6b5",
   "metadata": {},
   "source": [
    "## Modelling phase ðŸ§¬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c401195",
   "metadata": {},
   "source": [
    "There are two types of methods that are commonly used in collaborative filtering:\n",
    "\n",
    "Memory-based methods also referred to as neighborhood-based collaborative filtering algorithms, where ratings of user-item combinations are predicted based on their neighborhoods. These neighborhoods can be further defined as (1) User Based, and (2) Item Based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a small test dataframe to evaluate our models\n",
    "trial_df = df_train.copy()\n",
    "trial_df.drop(['timestamp'], axis=1, inplace=True)\n",
    "trial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684af546",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5e5c4",
   "metadata": {},
   "source": [
    "We select a portion of our data.\n",
    "Using more of the data gives a memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df = trial_df.head(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a5ab9",
   "metadata": {},
   "source": [
    "We will delete the timestamp column as we will not be using it. The Reader class is used to parse a file containing ratings. The ratings are from minimum of 0.5  to a maximum to 5.0.\n",
    "- Cosine similarity is a metric used to measure how similar two items are. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. The output value ranges from 0â€“1. 0 means no similarity, where as 1 means that both the items are 100% similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e7109",
   "metadata": {},
   "source": [
    "**Root Mean Square Error (RMSE)** is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are. RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit. Therefore, we will be using it to test the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0826fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training data\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "test_data = Dataset.load_from_df(trial_df[['userId','movieId','rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f51cf5",
   "metadata": {},
   "source": [
    "**Model 1:** user-user collaborative filtering: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b7590",
   "metadata": {},
   "source": [
    "In order to make a new recommendation to a user, user-user method roughly tries to identify users with the most similar â€œinteractions profileâ€ (nearest neighbours) in order to suggest items that are the most popular among these neighbours (and that are â€œnewâ€ to our user). This method is said to be â€œuser-centredâ€ as it represent users based on their interactions with items and evaluate distances between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5337ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities between users using cosine distance\n",
    "sim_options = {\"name\": \"cosine\",\n",
    "               \"user_based\": True}  \n",
    "\n",
    "# Evaluate the model \n",
    "user = KNNWithMeans(sim_options=sim_options)\n",
    "cv = cross_validate(user, test_data, cv=5, measures=['RMSE'], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5858f",
   "metadata": {},
   "source": [
    "**Model 2:** Item-item collaborative filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa613d",
   "metadata": {},
   "source": [
    "To make a new recommendation to a user, the idea of item-item method is to find items similar to the ones the user already â€œpositivelyâ€ interacted with. Two items are considered to be similar if most of the users that have interacted with both of them did it in a similar way. This method is said to be â€œitem-centredâ€ as it represent items based on interactions users had with them and evaluate distances between those items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities between items using cosine distance\n",
    "sim_options = {\"name\": \"cosine\",\n",
    "               \"user_based\": False}  \n",
    "\n",
    "# Fit the KNNwithmeans algorithm to the training set\n",
    "item_based = KNNWithMeans(sim_options=sim_options)\n",
    "\n",
    "# Evaluate the model \n",
    "cv = cross_validate(item_based, test_data, cv=5, measures=['RMSE'], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91497faa",
   "metadata": {},
   "source": [
    "We used 0.2% of the train data and observed the following:\n",
    "- The user based CF has an RMSE of 1.12\n",
    "- The item based CF has an RMSE of 1.08 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07edeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset\n",
    "data = {'User based':1.12,\n",
    "        'Item based':1.08,}\n",
    "courses = list(data.keys())\n",
    "values = list(data.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(courses, values, color =(0.2, 0.4, 0.6, 0.6),\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"RMSE score\")\n",
    "plt.title(\"RMSE score of selected models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e917d1",
   "metadata": {},
   "source": [
    "So we can conclude that the item based CF performs better. The lower the RMSE score, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d3523",
   "metadata": {},
   "source": [
    "Collaborative filtering (CF) is a widely used technique to generate recommendations. The basic principle is that recommendations can be made according to the ratings of like-minded users. However, CF inherently suffers from two severe issues, which are the\n",
    "problems;\n",
    "- Data sparsity refers to the difficulty in finding sufficient reliable similar users since in general the active users only rated a small portion of items;\n",
    "- Cold start refers to the difficulty in generating accurate recommendations for the cold users who only rated a small number of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc33f4",
   "metadata": {},
   "source": [
    " **Singular value decomposition (SVD)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240b872",
   "metadata": {},
   "source": [
    "The Singular Value Decomposition (SVD), a method from linear algebra that has been generally used as a dimensionality reduction technique in machine learning. SVD is a matrix factorisation technique, which reduces the number of features of a dataset by reducing the space dimension from N-dimension to K-dimension (where K<N). In the context of the recommender system, the SVD is used as a collaborative filtering technique. It uses a matrix structure where each row represents a user, and each column represents an item. The elements of this matrix are the ratings that are given to items by users.\n",
    "\n",
    "The factorisation of this matrix is done by the singular value decomposition. It finds factors of matrices from the factorisation of a high-level (user-item-rating) matrix. The essence of SVD is that it decomposes a matrix of any shape into a product of 3 matrices with nice mathematical properties: A=USVT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fc45",
   "metadata": {},
   "source": [
    "We will use the Surprise library that uses extremely powerful algorithms like Singular Value Decomposition (SVD) to minimise RMSE and give great recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f11a4a",
   "metadata": {},
   "source": [
    "Why use SVD over the covariance matrix?\n",
    "- Its faster \n",
    "- Singular values from SVD are sorted (we have to sort the eigenvalues in ascending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model \n",
    "svd = SVD(random_state=0)\n",
    "cv = cross_validate(svd, test_data, cv=5, measures=['RMSE'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cec5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train the model on the entire dataset \n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df_train[['userId','movieId','rating']], reader)\n",
    "trainingSet = data.build_full_trainset()\n",
    "svd.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72185bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the trained model\n",
    "pred = [svd.predict(df_test.userId[i],df_test.movieId[i]).est for i in df_test.index]\n",
    "df_test['rating'] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1967864",
   "metadata": {},
   "source": [
    "# Submission ðŸ“©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc96882",
   "metadata": {},
   "source": [
    "Prepare Submission File\n",
    "We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the data is the string 'Id'). The prediction column will use the name of the target field.\n",
    "\n",
    "We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff895e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire dataset\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df_train[['userId', 'movieId', 'rating']], reader)\n",
    "trainingSet = data.build_full_trainset()\n",
    "svd.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b1ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the trained model\n",
    "pred = [blo_test.predict(\n",
    "    df_test.userId[i], df_test.movieId[i]).est for i in df_test.index]\n",
    "df_test['rating'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the csv file for submission\n",
    "df_test['Id'] = df_test['userId'].astype(\n",
    "    str)+'_'+df_test['movieId'].astype(str)\n",
    "df_test = df_test[['Id', 'rating']]\n",
    "df_test.to_csv('sub20k.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c37a94",
   "metadata": {},
   "source": [
    "## Conclusion ðŸ‘‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc1613",
   "metadata": {},
   "source": [
    "According to our EDA, a disproportionate number of reviews were submitted for movies released in 1995, implying that the models we've generated are trained on slightly outdated data and could presumably be improved by additional training on a dataset with reviews for more recent movies. Furthermore, we would like to repeat this process on larger datasets, which would allow us to omit incomplete rows.\n",
    "\n",
    "We were able to perform both Content based filtering and Collaborative based filtering, although collaborative based filtering was the only algorithm which produced valid results with regard to modeling the dataset. The SVD model performed the best over-all and is the model used for the Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c597266",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0481684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
